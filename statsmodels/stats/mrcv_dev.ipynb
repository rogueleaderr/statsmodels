{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c342d0fbaacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpresidential2016\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "from statsmodels.datasets import presidential2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gjlondon/programming/open_source/statsmodels'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let us import app packages\n",
    "PACKAGE_PARENT = '/Users/gjlondon/programming/open_source/statsmodels'\n",
    "sys.path.append(os.path.normpath(PACKAGE_PARENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/usr/local/opt/libxml2/lib/python2.7/site-packages',\n",
       " '/Users/gjlondon/programming/open_source/statsmodels/statsmodels/stats',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python35.zip',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python3.5',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python3.5/plat-darwin',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python3.5/lib-dynload',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python3.5/site-packages',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg',\n",
       " '/Users/gjlondon/anaconda/envs/statsmodels-dev/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/gjlondon/.ipython',\n",
       " '/Users/gjlondon/programming/open_source/statsmodels']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'endog'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-16de81ea711b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresidential2016\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'endog'"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.datasets import presidential2016\n",
    "\n",
    "data = sm.datasets.presidential2016.load_pandas()\n",
    "data.endog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.datasets.utils.Dataset'>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import itertools\n",
    "from numpy import linalg\n",
    "from scipy.stats import chi2_contingency, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "\n",
    "class MRCVTable(object):\n",
    "    \"\"\"\n",
    "    Analyses that can be performed on a two-way contingency table that contains\n",
    "    'multiple response' categorical variables (e.g. 'choose all that apply' questions).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table : array-like\n",
    "        A contingency table.\n",
    "    shift_zeros : boolean\n",
    "        If True and any cell count is zero, add 0.5 to all values\n",
    "        in the table.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    table_orig : array-like\n",
    "        The original table is cached as `table_orig`.\n",
    "    marginal_probabilities : tuple of two ndarrays\n",
    "        The estimated row and column marginal distributions.\n",
    "    independence_probabilities : ndarray\n",
    "        Estimated cell probabilities under row/column independence.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    statsmodels.graphics.mosaicplot.mosaic\n",
    "    scipy.stats.chi2_contingency\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Definitions of residuals:\n",
    "        https://onlinecourses.science.psu.edu/stat504/node/86\n",
    "\n",
    "    Bilder and Loughlin (2004)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, table, rows_factor, columns_factor, shift_zeros=True):\n",
    "\n",
    "        self.rows_factor = rows_factor\n",
    "        self.columns_factor = columns_factor\n",
    "        self.table = table\n",
    "\n",
    "        if shift_zeros and (self.table.min() == 0):\n",
    "            self.table = self.table + 0.5\n",
    "\n",
    "    def __unicode__(self):\n",
    "        template = \"Contingency Table With Multi-Response Categorical Variables (MRCV's).\\nData:\\n{table}\"\n",
    "        return template.format(table=self.table)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__unicode__()\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(cls, data, I, J,\n",
    "                  rows_factor_name=\"factor_0\", columns_factor_name=\"factor_1\",\n",
    "                  shift_zeros=True):\n",
    "        \"\"\"\n",
    "        Construct a Table object from data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : array-like\n",
    "            The raw data, from which a contingency table is constructed\n",
    "            using the first two columns.\n",
    "        shift_zeros : boolean\n",
    "            If True and any cell count is zero, add 0.5 to all values\n",
    "            in the table.\n",
    "        I: The number of columns in the dataframe corresponding to the first factor\n",
    "        J: The number of columns in the dataframe corresponding to the second factor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        An MRCVTable instance.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            rows_data = data.iloc[:, 0:I]\n",
    "            columns_data = data.iloc[:, I:I + J]\n",
    "            rows_labels = rows_data.columns\n",
    "            columns_labels = columns_data.columns\n",
    "        else:\n",
    "            rows_data = data[:, 0:I]\n",
    "            columns_data = data[:, I:I + J]\n",
    "            rows_labels = [\"level_{}\".format(i) for i in range(0, I)]\n",
    "            columns_labels = [\"level_{}\".format(i) for i in range(I, I + J)]\n",
    "\n",
    "        rows_factor = Factor(rows_data, labels=rows_labels, name=rows_factor_name, orientation=\"wide\")\n",
    "        columns_factor = Factor(columns_data, labels=columns_labels, name=columns_factor_name, orientation=\"wide\")\n",
    "        table = cls.table_from_factors(columns_factor, rows_factor)\n",
    "        return cls(table, rows_factor, columns_factor, shift_zeros)\n",
    "\n",
    "    @classmethod\n",
    "    def table_from_factors(cls, columns_factor, rows_factor):\n",
    "        row_reshaped = rows_factor.reshape_for_contingency_table()\n",
    "        col_reshaped = columns_factor.reshape_for_contingency_table()\n",
    "        joint_dataframe = pd.merge(row_reshaped, col_reshaped, how=\"inner\",\n",
    "                                   on='observation_number', suffixes=(\"_row\", \"_col\"))\n",
    "        # without bool cast, '&' sometimes doesn't know how to compare types\n",
    "        joint_response = joint_dataframe['value_row'].astype(bool) & joint_dataframe['value_col'].astype(bool)\n",
    "        joint_dataframe['_joint_response'] = joint_response\n",
    "        table = pd.pivot_table(joint_dataframe,\n",
    "                               values='_joint_response',\n",
    "                               fill_value=0,\n",
    "                               index=['variable_row'],\n",
    "                               columns=['variable_col'],\n",
    "                               aggfunc=np.sum,)\n",
    "        return table\n",
    "\n",
    "    def _spmi_stat(self):\n",
    "        rows_data = self.rows_factor.data\n",
    "        columns_data = self.columns_factor.data\n",
    "        rows_levels = self.rows_factor.labels\n",
    "        columns_levels = self.columns_factor.labels\n",
    "        chis_spmi = pd.DataFrame(index=rows_levels, columns=columns_levels)\n",
    "        for i in range(0, len(rows_levels)):\n",
    "            for j in range(0, len(columns_levels)):\n",
    "                rows = np.array(rows_data[:, i])\n",
    "                columns = np.array(columns_data[:, j])\n",
    "                row_name = rows_levels[i]\n",
    "                col_name = columns_levels[j]\n",
    "                crosstab = pd.crosstab(index=rows, columns=columns, rownames=[row_name], colnames=[col_name])\n",
    "                chi2_results = chi2_contingency(crosstab, correction=False)\n",
    "                chi_squared_statistic, _, _, _ = chi2_results\n",
    "                chis_spmi.loc[row_name, col_name] = chi_squared_statistic\n",
    "        return chis_spmi\n",
    "    \n",
    "    def _test_for_single_pairwise_mutual_independence_using_bonferroni(self, observed):\n",
    "        chi2_survival_with_1_dof = partial(chi2.sf, df=1)\n",
    "        p_value_ij = observed.applymap(chi2_survival_with_1_dof)\n",
    "        p_value_min = p_value_ij.min().min()\n",
    "        bonferroni_correction_factor = self.rows_factor.level_count * self.columns_factor.level_count\n",
    "        table_p_value_bonferroni_corrected = bonferroni_correction_factor * p_value_min\n",
    "        cap = lambda x: min(x, 1)\n",
    "        pairwise_bonferroni_corrected_p_values = (p_value_ij * bonferroni_correction_factor).applymap(cap)\n",
    "        return table_p_value_bonferroni_corrected, pairwise_bonferroni_corrected_p_values\n",
    "    \n",
    "    def _test_for_single_pairwise_mutual_independence_using_rao_scott_2(self, observed):\n",
    "        W = self.rows_factor.as_dataframe()\n",
    "        Y = self.columns_factor.as_dataframe()\n",
    "        I = self.rows_factor.level_count\n",
    "        J = self.columns_factor.level_count\n",
    "        spmi_df = pd.concat([W, Y], axis=1)  # type: pd.DataFrame\n",
    "\n",
    "        def count_level_combinations(data, number_of_variables):\n",
    "            data = data.copy()  # don't modify original dataframe\n",
    "            level_arguments = [[0, 1] for i in range(0, number_of_variables)]\n",
    "            variables = data.columns\n",
    "            level_combinations = list(itertools.product(*level_arguments))\n",
    "            full_combinations = pd.DataFrame(level_combinations, columns=variables)\n",
    "            full_combinations[\"_dummy\"] = 0\n",
    "            data['_dummy'] = 1\n",
    "            data = pd.concat([data, full_combinations]).reset_index(drop=True)\n",
    "            grouped = data.groupby(list(variables))\n",
    "            return grouped.sum().reset_index()\n",
    "\n",
    "        W_count_ordered = count_level_combinations(W, I)\n",
    "        Y_count_ordered = count_level_combinations(Y, J)\n",
    "        n_count_ordered = count_level_combinations(spmi_df, I+J)\n",
    "\n",
    "        n = len(spmi_df)\n",
    "        G = (W_count_ordered.iloc[:, :-1]).T\n",
    "        H = (Y_count_ordered.iloc[:, :-1]).T\n",
    "        combined_counts = n_count_ordered.iloc[:, -1]\n",
    "        tau = combined_counts / n\n",
    "        m_row = G.dot(W_count_ordered.iloc[:, -1])\n",
    "        m_col = H.dot(Y_count_ordered.iloc[:, -1])\n",
    "        GH = np.kron(G, H)\n",
    "        m = GH.dot(combined_counts)\n",
    "\n",
    "        pi = m / n\n",
    "        pi_row = m_row / n\n",
    "        pi_col = m_col / n\n",
    "        j_2r = np.ones((2 ** I, 1))\n",
    "        i_2r = np.eye(2 ** I)\n",
    "        j_2c = np.ones((2 ** J, 1))\n",
    "        i_2c = np.eye(2 ** J)\n",
    "\n",
    "        G_ij = G.dot(np.kron(i_2r, j_2c.T))\n",
    "        H_ji = H.dot(np.kron(j_2r.T, i_2c))\n",
    "\n",
    "        H_kron = np.kron(pi_row, H_ji.T).T  # extra .T's b/c Python handles vector/matrix kronecker differently than R\n",
    "        G_kron = np.kron(G_ij.T, pi_col).T  # extra .T's b/c Python handles vector/matrix kronecker differently than R\n",
    "        F = GH - H_kron - G_kron\n",
    "\n",
    "        mult_cov = np.diag(tau) - np.outer(tau, tau.T)\n",
    "        sigma = F.dot(mult_cov.dot(F.T))\n",
    "\n",
    "        D = np.diag(np.kron(pi_row, pi_col) * np.kron(1 - pi_row, 1 - pi_col))\n",
    "        Di_sigma = np.diag(1 / np.diag(D)).dot(sigma)\n",
    "        eigenvalues, eigenvectors = linalg.eig(Di_sigma)\n",
    "        Di_sigma_eigen = np.real(eigenvalues)\n",
    "        sum_Di_sigma_eigen_sq = (Di_sigma_eigen ** 2).sum()\n",
    "\n",
    "        observed_X_sq_S = observed.sum().sum()\n",
    "        X_sq_S_rs2 = I * J * observed_X_sq_S / sum_Di_sigma_eigen_sq\n",
    "        df_rs2 = (I ** 2) * (J ** 2) / sum_Di_sigma_eigen_sq\n",
    "        X_sq_S_p_value_rs2 = chi2.sf(X_sq_S_rs2, df=df_rs2)\n",
    "        return X_sq_S_p_value_rs2\n",
    "\n",
    "\n",
    "class Factor(object):\n",
    "    def __init__(self, data, labels, name, orientation=\"wide\"):\n",
    "        self.name = name\n",
    "        self.labels = labels\n",
    "        self.data = np.asarray(data, dtype=np.float64)\n",
    "        self.orientation = orientation\n",
    "\n",
    "    def __unicode__(self):\n",
    "        return \"Factor: {name}\\nColumns:{columns}\\nData:\\n{data}\".format(name=self.name, columns=self.labels,\n",
    "                                                                         data=self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__unicode__()\n",
    "\n",
    "    def reshape_for_contingency_table(self):\n",
    "        frame = self.as_dataframe()\n",
    "        frame['observation_number'] = frame.index\n",
    "        return pd.melt(frame, id_vars=\"observation_number\")\n",
    "\n",
    "    @property\n",
    "    def level_count(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def as_dataframe(self):\n",
    "        return pd.DataFrame(self.data, columns=self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_factor = Factor(data.data.iloc[:, :6], data.data.columns[:6], \"expected_choice\", orientation=\"wide\")\n",
    "column_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "#crosstab_with_marginal_totals.fillna(0, inplace=True)  # fill value above doesn't seem to get all the na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_response_factor = Factor(data.data.iloc[:, :6], data.data.columns[:6], \"expected_choice\", orientation=\"wide\")\n",
    "multiple_response_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "\n",
    "single_response_dataframe = single_response_factor.as_dataframe()\n",
    "multiple_response_dataframe = multiple_response_factor.as_dataframe()\n",
    "\n",
    "multiple_response_dataframe.head()\n",
    "\n",
    "melted = pd.melt(single_response_dataframe.reset_index(), id_vars=\"index\") \\\n",
    "    .rename(columns={\"index\": \"response_id\",\n",
    "                     \"value\": \"selected\",\n",
    "                     \"variable\": \"single_response_level\"})\n",
    "melted = melted[melted.selected == 1]\n",
    "single_response_melted = melted\n",
    "multiple_response_dataframe.index.name = \"response_id\"\n",
    "multiple_response_dataframe = multiple_response_dataframe.reset_index()\n",
    "joint_dataframe = pd.merge(single_response_melted.iloc[:, :2], multiple_response_dataframe, how=\"inner\", on=\"response_id\")\n",
    "joint_dataframe.head()\n",
    "\n",
    "mmi_chi_squared_by_cell = pd.Series(index=multiple_response_factor.labels)\n",
    "single_response_column = joint_dataframe.single_response_level\n",
    "\n",
    "for c in multiple_response_factor.labels:\n",
    "    multiple_response_column = joint_dataframe.loc[:, c]\n",
    "    crosstab = pd.crosstab(single_response_column, multiple_response_column)\n",
    "    chi2_results = chi2_contingency(crosstab, correction=False)\n",
    "    chi_squared_statistic, table_p_value, degrees_of_freedom, expected_counts = chi2_results\n",
    "    mmi_chi_squared_by_cell.loc[c] = chi_squared_statistic\n",
    "mmi_chi_squared_by_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = MRCVTable.from_data(data.data, 6, 5, shift_zeros=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed = table._spmi_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6696641484241839e-14"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table._test_for_single_pairwise_mutual_independence_using_bonferroni(observed)\n",
    "table._test_for_single_pairwise_mutual_independence_using_rao_scott_2(observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six import reraise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class MRCVTable(object):\n",
    "    \"\"\"\n",
    "    Analyses that can be performed on a two-way contingency table that contains\n",
    "    'multiple response' categorical variables (e.g. 'choose all that apply' questions).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table : array-like\n",
    "        A contingency table.\n",
    "    shift_zeros : boolean\n",
    "        If True and any cell count is zero, add 0.5 to all values\n",
    "        in the table.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    table_orig : array-like\n",
    "        The original table is cached as `table_orig`.\n",
    "    marginal_probabilities : tuple of two ndarrays\n",
    "        The estimated row and column marginal distributions.\n",
    "    independence_probabilities : ndarray\n",
    "        Estimated cell probabilities under row/column independence.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    statsmodels.graphics.mosaicplot.mosaic\n",
    "    scipy.stats.chi2_contingency\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Definitions of residuals:\n",
    "        https://onlinecourses.science.psu.edu/stat504/node/86\n",
    "\n",
    "    Bilder and Loughlin (2004)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, row_factors, column_factors, shift_zeros=True):\n",
    "\n",
    "        self.row_factors = row_factors\n",
    "        self.column_factors = column_factors\n",
    "        self.table = self.table_from_factors(row_factors, column_factors)\n",
    "        # TODO george@survata.com shift zeros\n",
    "\n",
    "    def __unicode__(self):\n",
    "        template = \"Contingency Table With Multi-Response Categorical Variables (MRCV's).\\nData:\\n{table}\"\n",
    "        return template.format(table=self.table)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.table.__repr__()\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(cls, data, I, J,\n",
    "                  rows_factor_name=\"factor_0\", columns_factor_name=\"factor_1\",\n",
    "                  shift_zeros=True):\n",
    "        \"\"\"\n",
    "        Construct a Table object from data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : array-like\n",
    "            The raw data, from which a contingency table is constructed\n",
    "            using the first two columns.\n",
    "        shift_zeros : boolean\n",
    "            If True and any cell count is zero, add 0.5 to all values\n",
    "            in the table.\n",
    "        I: The number of columns in the dataframe corresponding to the first factor\n",
    "        J: The number of columns in the dataframe corresponding to the second factor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        An MRCVTable instance.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            rows_data = data.iloc[:, 0:I]\n",
    "            columns_data = data.iloc[:, I:I + J]\n",
    "            rows_labels = rows_data.columns\n",
    "            columns_labels = columns_data.columns\n",
    "        else:\n",
    "            rows_data = data[:, 0:I]\n",
    "            columns_data = data[:, I:I + J]\n",
    "            rows_labels = [\"level_{}\".format(i) for i in range(0, I)]\n",
    "            columns_labels = [\"level_{}\".format(i) for i in range(I, I + J)]\n",
    "\n",
    "        rows_factor = Factor(rows_data, labels=rows_labels, name=rows_factor_name, orientation=\"wide\")\n",
    "        columns_factor = Factor(columns_data, labels=columns_labels, name=columns_factor_name, orientation=\"wide\")\n",
    "        table = cls.table_from_factors([rows_factor], [columns_factor])\n",
    "        return cls(table, rows_factor, columns_factor, shift_zeros)\n",
    "\n",
    "    @classmethod\n",
    "    def table_from_factors(cls, row_factors, column_factors):\n",
    "        column_factor, row_factor = cls._extract_and_validate_factors(column_factors, row_factors)\n",
    "        row_reshaped = row_factor.reshape_for_contingency_table()\n",
    "        col_reshaped = column_factor.reshape_for_contingency_table()\n",
    "        joint_dataframe = pd.merge(row_reshaped, col_reshaped, how=\"inner\",\n",
    "                                   on='observation_number', suffixes=(\"_row\", \"_col\"))\n",
    "        # without bool cast, '&' sometimes doesn't know how to compare types\n",
    "        joint_response = joint_dataframe['value_row'].astype(bool) & joint_dataframe['value_col'].astype(bool)\n",
    "        joint_dataframe['_joint_response'] = joint_response\n",
    "        table = pd.pivot_table(joint_dataframe,\n",
    "                               values='_joint_response',\n",
    "                               fill_value=0,\n",
    "                               index=['variable_row'],\n",
    "                               columns=['variable_col'],\n",
    "                               aggfunc=np.sum,)\n",
    "        return table\n",
    "\n",
    "    @classmethod\n",
    "    def _extract_and_validate_factors(cls, column_factors, row_factors):\n",
    "        try:\n",
    "            try:\n",
    "                if len(row_factors) > 1:\n",
    "                    msg = \"we don't currently support tables with more than one factor on the rows\"\n",
    "                    raise NotImplementedError(msg)\n",
    "                row_factor = row_factors[0]\n",
    "            except TypeError:\n",
    "                if isinstance(row_factors, Factor):\n",
    "                    row_factor = row_factors\n",
    "                else:\n",
    "                    msg = \"row_factors must be either a list of Factors or a Factor instance\"\n",
    "                    raise NotImplementedError(msg)\n",
    "            try:\n",
    "                if len(column_factors) > 2:\n",
    "                    msg = \"we don't currently support tables with more than one factor on the columns\"\n",
    "                    raise NotImplementedError(msg)\n",
    "                column_factor = column_factors[0]\n",
    "            except TypeError as e:\n",
    "                if isinstance(column_factors, Factor):\n",
    "                    column_factor = column_factors\n",
    "                else:\n",
    "                    msg = \"column_factors must be either a list of Factors or a Factor instance\"\n",
    "                    raise NotImplementedError(msg)\n",
    "            return column_factor, row_factor\n",
    "        except IndexError:\n",
    "            explanation = (\"Please be sure to pass at \"\n",
    "                           \"least 1 factor on both the rows and columns\")\n",
    "            raise IndexError(explanation)\n",
    "\n",
    "    def _calculate_pairwise_chi2s_for_MMI_item_response_table(self,\n",
    "                                                              single_response_factor,\n",
    "                                                              multiple_response_factor):\n",
    "        \"\"\"\n",
    "\n",
    "        :param single_response_factor: \n",
    "        :param multiple_response_factor: \n",
    "        \"\"\"\n",
    "        single_response_dataframe = single_response_factor.as_dataframe()\n",
    "        multiple_response_dataframe = multiple_response_factor.as_dataframe()\n",
    "\n",
    "        single_response_melted = pd.melt(single_response_dataframe.reset_index(), id_vars=\"index\") \\\n",
    "            .rename(columns={\"index\": \"response_id\",\n",
    "                             \"value\": \"selected\",\n",
    "                             \"variable\": \"single_response_level\"})\n",
    "        single_response_melted = single_response_melted[single_response_melted.selected == 1]\n",
    "\n",
    "        multiple_response_dataframe.index.name = \"response_id\"\n",
    "        multiple_response_dataframe = multiple_response_dataframe.reset_index()\n",
    "        joint_dataframe = pd.merge(single_response_melted.iloc[:, :2], multiple_response_dataframe, how=\"inner\",\n",
    "                                   on=\"response_id\")\n",
    "\n",
    "        mmi_chi_squared_by_cell = pd.Series(index=multiple_response_factor.labels)\n",
    "        single_response_column = joint_dataframe.single_response_level\n",
    "        for c in multiple_response_factor.labels:\n",
    "            multiple_response_column = joint_dataframe.loc[:, c]\n",
    "            crosstab = pd.crosstab(single_response_column, multiple_response_column)\n",
    "            chi2_results = chi2_contingency(crosstab, correction=False)\n",
    "            chi_squared_statistic, _, _, _ = chi2_results\n",
    "            mmi_chi_squared_by_cell.loc[c] = chi_squared_statistic\n",
    "        return mmi_chi_squared_by_cell\n",
    "\n",
    "    def _calculate_pairwise_chi2s_for_SPMI_item_response_table(self, rows_factor, columns_factor):\n",
    "        rows_data = rows_factor.data\n",
    "        columns_data = columns_factor.data\n",
    "        rows_levels = rows_factor.labels\n",
    "        columns_levels = columns_factor.labels\n",
    "        chis_spmi = pd.DataFrame(index=rows_levels, columns=columns_levels)\n",
    "        for i in range(0, len(rows_levels)):\n",
    "            for j in range(0, len(columns_levels)):\n",
    "                rows = np.array(rows_data[:, i])\n",
    "                columns = np.array(columns_data[:, j])\n",
    "                row_name = rows_levels[i]\n",
    "                col_name = columns_levels[j]\n",
    "                crosstab = pd.crosstab(index=rows, columns=columns, rownames=[row_name], colnames=[col_name])\n",
    "                chi2_results = chi2_contingency(crosstab, correction=False)\n",
    "                chi_squared_statistic, _, _, _ = chi2_results\n",
    "                chis_spmi.loc[row_name, col_name] = chi_squared_statistic\n",
    "        return chis_spmi\n",
    "\n",
    "    def _test_for_single_pairwise_mutual_independence_using_bonferroni(self, row_factor, column_factor):\n",
    "        observed = self._calculate_pairwise_chi2s_for_SPMI_item_response_table(row_factor, \n",
    "                                                                               column_factor)\n",
    "        chi2_survival_with_1_dof = partial(chi2.sf, df=1)\n",
    "        p_value_ij = observed.applymap(chi2_survival_with_1_dof)\n",
    "        p_value_min = p_value_ij.min().min()\n",
    "        bonferroni_correction_factor = row_factor.level_count * column_factor.level_count\n",
    "        table_p_value_bonferroni_corrected = bonferroni_correction_factor * p_value_min\n",
    "        cap = lambda x: min(x, 1)\n",
    "        pairwise_bonferroni_corrected_p_values = (p_value_ij * bonferroni_correction_factor).applymap(cap)\n",
    "        return table_p_value_bonferroni_corrected, pairwise_bonferroni_corrected_p_values\n",
    "\n",
    "    def _test_for_single_pairwise_mutual_independence_using_bootstrap(self, observed):\n",
    "        W = self.row_factors.as_dataframe()\n",
    "        Y = self.column_factors.as_dataframe()\n",
    "        I = self.row_factors.level_count\n",
    "        J = self.column_factors.level_count\n",
    "        spmi_df = pd.concat([W, Y], axis=1)  # type: pd.DataFrame\n",
    "        chi2_survival_with_1_dof = partial(chi2.sf, df=1)\n",
    "\n",
    "        b_max = 1000\n",
    "        n = len(spmi_df)\n",
    "        q1 = spmi_df.iloc[:, :I + 1]\n",
    "        q2 = spmi_df.iloc[:, I + 1:I + J]\n",
    "        X_sq_S_star = []\n",
    "        X_sq_S_ij_star = pd.DataFrame(index=range(0, I * J), columns=range(0, b_max))\n",
    "        p_value_b_min = []\n",
    "        p_value_b_prod = []\n",
    "        rows_factor_name = self.row_factors.name\n",
    "        rows_factor_labels = self.row_factors.labels\n",
    "        columns_factor_name = self.column_factors.name\n",
    "        columns_factor_labels = self.column_factors.labels\n",
    "        for i in range(0, b_max):\n",
    "            # pd.concat requires unique indexes...sampling with replacement produces duplicates\n",
    "            q1_sample = q1.sample(n, replace=True).reset_index(drop=True)\n",
    "            q2_sample = q2.sample(n, replace=True).reset_index(drop=True)\n",
    "\n",
    "            sample_rows_factor = Factor(q1_sample, rows_factor_labels, rows_factor_name)\n",
    "            sample_columns_factor = Factor(q2_sample, columns_factor_labels, columns_factor_name)\n",
    "            stat_star = self._calculate_pairwise_chi2s_for_SPMI_item_response_table(sample_rows_factor,\n",
    "                                                                                    sample_columns_factor)\n",
    "            X_sq_S = stat_star.sum().sum()\n",
    "            X_sq_S_star.append(X_sq_S)\n",
    "            X_sq_S_ij_star.append(stat_star)\n",
    "            p_value_ij = stat_star.applymap(chi2_survival_with_1_dof)\n",
    "            p_value_min = p_value_ij.min().min()\n",
    "            p_value_prod = p_value_ij.prod().prod()\n",
    "            p_value_b_min.append(p_value_min)\n",
    "            p_value_b_prod.append(p_value_prod)\n",
    "\n",
    "        observed = self._calculate_pairwise_chi2s_for_SPMI_item_response_table(self.row_factors,\n",
    "                                                                               self.column_factors)\n",
    "        observed_X_sq_S = observed.sum().sum()\n",
    "        p_value_ij = observed.applymap(chi2_survival_with_1_dof)\n",
    "        p_value_min = p_value_ij.min().min()\n",
    "\n",
    "        p_value_boot = np.mean(X_sq_S_star >= observed_X_sq_S)\n",
    "        print(p_value_boot)\n",
    "\n",
    "        p_value_boot_min_overall = np.mean(p_value_b_min <= p_value_min)\n",
    "        print(p_value_boot_min_overall)\n",
    "\n",
    "    def _test_for_single_pairwise_mutual_independence_using_rao_scott_2(self, row_factor,\n",
    "                                                                        column_factor):\n",
    "        observed = self._calculate_pairwise_chi2s_for_SPMI_item_response_table(row_factor, \n",
    "                                                                               column_factor)\n",
    "        W = row_factor.as_dataframe()\n",
    "        Y = column_factor.as_dataframe()\n",
    "        I = row_factor.level_count\n",
    "        J = column_factor.level_count\n",
    "        spmi_df = pd.concat([W, Y], axis=1)  # type: pd.DataFrame\n",
    "\n",
    "        def count_level_combinations(data, number_of_variables):\n",
    "            data = data.copy()  # don't modify original dataframe\n",
    "            level_arguments = [[0, 1] for i in range(0, number_of_variables)]\n",
    "            variables = data.columns\n",
    "            level_combinations = list(itertools.product(*level_arguments))\n",
    "            full_combinations = pd.DataFrame(level_combinations, columns=variables)\n",
    "            full_combinations[\"_dummy\"] = 0\n",
    "            data['_dummy'] = 1\n",
    "            data = pd.concat([data, full_combinations]).reset_index(drop=True)\n",
    "            grouped = data.groupby(list(variables))\n",
    "            return grouped.sum().reset_index()\n",
    "\n",
    "        W_count_ordered = count_level_combinations(W, I)\n",
    "        Y_count_ordered = count_level_combinations(Y, J)\n",
    "        n_count_ordered = count_level_combinations(spmi_df, I+J)\n",
    "\n",
    "        n = len(spmi_df)\n",
    "        G = (W_count_ordered.iloc[:, :-1]).T\n",
    "        H = (Y_count_ordered.iloc[:, :-1]).T\n",
    "        combined_counts = n_count_ordered.iloc[:, -1]\n",
    "        tau = combined_counts / n\n",
    "        m_row = G.dot(W_count_ordered.iloc[:, -1])\n",
    "        m_col = H.dot(Y_count_ordered.iloc[:, -1])\n",
    "        GH = np.kron(G, H)\n",
    "        m = GH.dot(combined_counts)\n",
    "\n",
    "        pi = m / n\n",
    "        pi_row = m_row / n\n",
    "        pi_col = m_col / n\n",
    "        j_2r = np.ones((2 ** I, 1))\n",
    "        i_2r = np.eye(2 ** I)\n",
    "        j_2c = np.ones((2 ** J, 1))\n",
    "        i_2c = np.eye(2 ** J)\n",
    "\n",
    "        G_ij = G.dot(np.kron(i_2r, j_2c.T))\n",
    "        H_ji = H.dot(np.kron(j_2r.T, i_2c))\n",
    "\n",
    "        # extra .T's b/c Python handles vector/matrix kronecker differently than R\n",
    "        H_kron = np.kron(pi_row, H_ji.T).T\n",
    "        G_kron = np.kron(G_ij.T, pi_col).T\n",
    "        F = GH - H_kron - G_kron\n",
    "\n",
    "        mult_cov = np.diag(tau) - np.outer(tau, tau.T)\n",
    "        sigma = F.dot(mult_cov.dot(F.T))\n",
    "\n",
    "        D = np.diag(np.kron(pi_row, pi_col) * np.kron(1 - pi_row, 1 - pi_col))\n",
    "        Di_sigma = np.diag(1 / np.diag(D)).dot(sigma)\n",
    "        eigenvalues, eigenvectors = linalg.eig(Di_sigma)\n",
    "        Di_sigma_eigen = np.real(eigenvalues)\n",
    "        sum_Di_sigma_eigen_sq = (Di_sigma_eigen ** 2).sum()\n",
    "\n",
    "        observed_X_sq_S = observed.sum().sum()\n",
    "        X_sq_S_rs2 = I * J * observed_X_sq_S / sum_Di_sigma_eigen_sq\n",
    "        df_rs2 = (I ** 2) * (J ** 2) / sum_Di_sigma_eigen_sq\n",
    "        X_sq_S_p_value_rs2 = chi2.sf(X_sq_S_rs2, df=df_rs2)\n",
    "        return X_sq_S_p_value_rs2\n",
    "\n",
    "    def _test_for_marginal_mutual_independence_using_bonferroni_correction(self,\n",
    "                                                                           single_response_factor,\n",
    "                                                                           multiple_response_factor):\n",
    "        mmi_pairwise_chis = self._calculate_pairwise_chi2s_for_MMI_item_response_table(single_response_factor,\n",
    "                                                                                       multiple_response_factor)\n",
    "        # TODO check\n",
    "        c = len(multiple_response_factor.labels)\n",
    "        r = len(multiple_response_factor.labels)\n",
    "\n",
    "        chi2_survival_with_1_dof = partial(chi2.sf, df=(r - 1))\n",
    "\n",
    "        p_value_ij = mmi_pairwise_chis.apply(chi2_survival_with_1_dof)\n",
    "        p_value_min = p_value_ij.min()\n",
    "\n",
    "        bonferroni_correction_factor = c\n",
    "        table_p_value_bonferroni_corrected = min(bonferroni_correction_factor * p_value_min, 1)\n",
    "        pairwise_bonferroni_corrected_p_values = (p_value_ij * bonferroni_correction_factor).apply(lambda x: min(x, 1))\n",
    "        return table_p_value_bonferroni_corrected, pairwise_bonferroni_corrected_p_values\n",
    "\n",
    "    def _test_for_marginal_mutual_independence_using_rao_scott_2(self,\n",
    "                                                                 single_response_factor,\n",
    "                                                                 multiple_response_factor):\n",
    "        W = single_response_factor.as_dataframe()\n",
    "        if not isinstance(W, pd.Series):\n",
    "            W = W.iloc[:, 0]\n",
    "        Y = multiple_response_factor.as_dataframe()\n",
    "        n = len(W)\n",
    "        I = 1  # single response variable must have exactly one column\n",
    "        J = len(Y.columns)\n",
    "        c = J\n",
    "        r = len(W.unique())\n",
    "\n",
    "        def conjoint_combinations(srcv, mrcv):\n",
    "            number_of_variables = 1 + len(mrcv.columns)\n",
    "            srcv = srcv.copy()  # don't modify original dataframe\n",
    "            mrcv = mrcv.copy()  # don't modify original dataframe\n",
    "            srcv.name = \"srcv\"\n",
    "            srcv_level_arguments = srcv.unique()\n",
    "            mrcv_level_arguments = [[0, 1] for i in range(0, number_of_variables - 1)]\n",
    "            level_arguments = [list(srcv_level_arguments), ] + mrcv_level_arguments\n",
    "            variables = ['srcv', ] + list(mrcv.columns)\n",
    "            level_combinations = list(itertools.product(*level_arguments))\n",
    "            full_combinations = pd.DataFrame(level_combinations, columns=variables)\n",
    "            full_combinations[\"_dummy\"] = 0\n",
    "            data = pd.concat([srcv, mrcv], axis=1)\n",
    "            data.srcv.value_counts()\n",
    "            data['_dummy'] = 1\n",
    "            data = pd.concat([data, full_combinations]).reset_index(drop=True)\n",
    "            grouped = data.groupby(list(variables))\n",
    "            result = grouped.sum().reset_index()\n",
    "            return result\n",
    "\n",
    "        def count_level_combinations(data, number_of_variables):\n",
    "            data = data.copy()  # don't modify original dataframe\n",
    "            level_arguments = [[0, 1] for i in range(0, number_of_variables)]\n",
    "            variables = data.columns\n",
    "            level_combinations = list(itertools.product(*level_arguments))\n",
    "            full_combinations = pd.DataFrame(level_combinations, columns=variables)\n",
    "            full_combinations[\"_dummy\"] = 0\n",
    "            data['_dummy'] = 1\n",
    "            data = pd.concat([data, full_combinations]).reset_index(drop=True)\n",
    "            grouped = data.groupby(list(variables))\n",
    "            return grouped.sum().reset_index()\n",
    "\n",
    "        Y_count_ordered = count_level_combinations(Y, J)\n",
    "        n_count_ordered = conjoint_combinations(W, Y)\n",
    "        Y_count_ordered.sort_values(\"_dummy\")\n",
    "\n",
    "        # need make n_iplus be in same order as SRCV options in the n_counts_ordered_table\n",
    "        srcv_table_order = n_count_ordered.groupby('srcv').first().index.values\n",
    "        n_iplus = W.value_counts().reindex(srcv_table_order)\n",
    "        tau = n_count_ordered.iloc[:, -1].astype(int) / np.repeat(n_iplus, repeats=(2 ** c)).reset_index(drop=True)\n",
    "        G_tilde = Y_count_ordered.iloc[:, :-1].T\n",
    "        I_r = np.eye(r)\n",
    "        G = np.kron(I_r, G_tilde)\n",
    "        pi = G.dot(tau)\n",
    "        m = pi * np.repeat(n_iplus, c)\n",
    "        a_i = n_iplus / n\n",
    "        pi_not_j = (1 / n) * np.kron(np.ones(r), np.eye(c)).dot(m)\n",
    "        j_r = np.ones(r)\n",
    "        pi_not = np.kron(j_r, pi_not_j)\n",
    "        I_rc = np.eye(r * c)\n",
    "        I_c = np.eye(c)\n",
    "        J_rr = np.ones((r, r))\n",
    "        A = np.diag(a_i)\n",
    "        H = I_rc - np.kron(J_rr.dot(A), I_c)\n",
    "        D = np.kron(np.diag(n / n_iplus), np.diag(pi_not_j) * (1 - pi_not_j))\n",
    "        v_dim = r * (2 ** c)\n",
    "        V = np.zeros((v_dim, v_dim))\n",
    "\n",
    "        # TODO george@survata.com check starting 1 vs 0\n",
    "        for i in range(1, r):\n",
    "            a = ((i - 1) * (2 ** c) + 1) - 1\n",
    "            b = ((i - 1) * (2 ** c) + (2 ** c)) - 1\n",
    "            tau_range = tau[a:b]\n",
    "            a_v = (1 / a_i[i - 1])\n",
    "            tau_diag = np.diag(tau_range)\n",
    "            tau_tcrossproduct = np.outer(tau_range, tau_range.T)\n",
    "            v = a_v * (tau_diag - tau_tcrossproduct)\n",
    "            V[a:b, a:b] = v\n",
    "\n",
    "        D_diag = np.diag(1 / np.diag(D))\n",
    "        D_diag.dot(H).dot(G)\n",
    "        Di_HGVGH = D_diag.dot(H).dot(G).dot(V.dot(G.T).dot(H.T))\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(Di_HGVGH)\n",
    "        Di_HGVGH_eigen = np.real(eigenvalues)\n",
    "        sum_Di_HGVGH_eigen_sq = (Di_HGVGH_eigen ** 2).sum()\n",
    "        observed = self._calculate_pairwise_chi2s_for_MMI_item_response_table(single_response_factor,\n",
    "                                                                              multiple_response_factor)\n",
    "        observed_X_sq = observed.sum()\n",
    "        X_sq_S_rs2 = ((r - 1) * c) * observed_X_sq / sum_Di_HGVGH_eigen_sq\n",
    "        df_rs2 = ((r - 1) ** 2) * (c ** 2) / sum_Di_HGVGH_eigen_sq\n",
    "        X_sq_S_p_value_rs2 = chi2.sf(X_sq_S_rs2, df=df_rs2)\n",
    "        return X_sq_S_p_value_rs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Factor(object):\n",
    "    def __init__(self, data, labels, name, orientation=\"wide\"):\n",
    "        self.name = name\n",
    "        self.labels = labels\n",
    "        self.data = np.asarray(data, dtype=np.float64)\n",
    "        self.orientation = orientation\n",
    "\n",
    "    def __unicode__(self):\n",
    "        return \"Factor: {name}\\nColumns:{columns}\\nData:\\n{data}\".format(name=self.name, columns=self.labels,\n",
    "                                                                         data=self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__unicode__()\n",
    "\n",
    "    def reshape_for_contingency_table(self):\n",
    "        frame = self.as_dataframe()\n",
    "        frame['observation_number'] = frame.index\n",
    "        return pd.melt(frame, id_vars=\"observation_number\")\n",
    "\n",
    "    @property\n",
    "    def level_count(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def as_dataframe(self):\n",
    "        return pd.DataFrame(self.data, columns=self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose, assert_equal\n",
    "\n",
    "def test_calculate_pairwise_chi2s_for_MMI_item_response_table():\n",
    "    rows_factor = Factor(data.data.iloc[:, :6], data.data.columns[:6], \"expected_choice\", orientation=\"wide\")\n",
    "    columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "    multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "    pairwise_chis = multiple_response_table._calculate_pairwise_chi2s_for_MMI_item_response_table(rows_factor, columns_factor)\n",
    "    expected = np.array([ 27.49359188,  36.51100003,  33.06527619,  19.30508587,  16.2387889 ])\n",
    "    assert_allclose(pairwise_chis.values, expected)\n",
    "    \n",
    "def test_calculate_pairwise_chi2s_for_SPMI_item_response_table():    \n",
    "    rows_factor = Factor(data.data.iloc[:, 11:], data.data.columns[11:], \"reasons_undecided\", orientation=\"wide\")\n",
    "    columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "    multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "    pairwise_chis = multiple_response_table._calculate_pairwise_chi2s_for_SPMI_item_response_table(rows_factor, columns_factor)\n",
    "    expected = np.array([[11.057399043055453, 7.0433141769624967, 11.76419998565429,\n",
    "            6.6835142302920527, 16.129398885445724],\n",
    "           [12.510475178886146, 0.0031863099132473853, 0.5586384786490618,\n",
    "            2.0740299456382045, 0.96428862745228061],\n",
    "           [17.27417447368591, 2.7434061504889233, 9.7400222125093734,\n",
    "            10.013109401042946, 22.869451447577219],\n",
    "           [0.022869776364994012, 1.3818184772649058, 0.4021032851909711,\n",
    "            0.019325630680345859, 8.5606054391027779],\n",
    "           [5.2158331412745191, 4.0136842422000854, 16.088255726022293,\n",
    "            4.4883332473823732, 0.23695713171009866]], dtype=np.float64)\n",
    "    observed = pairwise_chis.values.astype(np.float64)\n",
    "    assert_allclose(observed, expected)\n",
    "\n",
    "def test_multiple_mutual_independence_true():\n",
    "    assert False\n",
    "\n",
    "def test_multiple_mutual_independence_true_using_bonferroni():\n",
    "    rows_factor = Factor(data.data.iloc[:, :6], data.data.columns[:6], \"expected_choice\", orientation=\"wide\")\n",
    "    columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "    multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "    table_p_value, cellwise_p_values = multiple_response_table._test_for_marginal_mutual_independence_using_bonferroni_correction(rows_factor, columns_factor)\n",
    "    assert table_p_value - 1.1356954469547448e-06 <= 0.00001\n",
    "    expected = np.array([7.89787134e-05, 1.13569545e-06, 5.79140286e-06,\n",
    "             3.42276565e-03, 1.35746237e-02])\n",
    "    assert_allclose(cellwise_p_values, expected)\n",
    "\n",
    "def test_multiple_mutual_independence_true_using_rao_scott_2():\n",
    "    rows_factor = Factor(data.data.iloc[:, :6], data.data.columns[:6], \"expected_choice\", orientation=\"wide\")\n",
    "    columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "    multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "    table_p_value = multiple_response_table._test_for_marginal_mutual_independence_using_rao_scott_2(rows_factor, columns_factor)\n",
    "    assert table_p_value - 0.0 <= 0.00001\n",
    "\n",
    "def test_test_multiple_mutual_independence_false():\n",
    "    assert False\n",
    "\n",
    "def test_spmi_true_using_bonferroni():\n",
    "    rows_factor = Factor(data.data.iloc[:, 11:], data.data.columns[11:], \"reasons_undecided\", orientation=\"wide\")\n",
    "    columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "    multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "    table_p_value, cellwise_p_values = multiple_response_table._test_for_single_pairwise_mutual_independence_using_bonferroni(rows_factor, columns_factor)\n",
    "    assert table_p_value - 4.3346430242129665e-05 <= 0.000001\n",
    "    expected = np.array([[  2.20834933e-02,   1.98904185e-01,   1.50952071e-02,\n",
    "              2.43271486e-01,   1.47896365e-03],\n",
    "           [  1.01169167e-02,   1.00000000e+00,   1.00000000e+00,\n",
    "              1.00000000e+00,   1.00000000e+00],\n",
    "           [  8.08886522e-04,   1.00000000e+00,   4.50746797e-02,\n",
    "              3.88574715e-02,   4.33464302e-05],\n",
    "           [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
    "              1.00000000e+00,   8.58787906e-02],\n",
    "           [  5.59553004e-01,   1.00000000e+00,   1.51144522e-03,\n",
    "              8.53173376e-01,   1.00000000e+00]])\n",
    "    assert_allclose(cellwise_p_values.values, expected)\n",
    "\n",
    "\n",
    "def test_spmi_true_using_rao_scott_2():\n",
    "    rows_factor = Factor(data.data.iloc[:, 11:], data.data.columns[11:], \"reasons_undecided\", orientation=\"wide\")\n",
    "    columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "    multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "    table_p_value = multiple_response_table._test_for_single_pairwise_mutual_independence_using_rao_scott_2(rows_factor, columns_factor)\n",
    "    assert table_p_value - 6.2565046672587634e-18 <= 0.000001\n",
    "    \n",
    "def test_single_pairwise_mutual_independence_true():\n",
    "    assert False\n",
    "\n",
    "\n",
    "def test_single_pairwise_mutual_independence_false():\n",
    "    assert False\n",
    "\n",
    "\n",
    "def test_MRCV_table_from_data():\n",
    "    assert False\n",
    "\n",
    "\n",
    "def test_MRCV_table_from_factors():\n",
    "    assert False\n",
    "\n",
    "\n",
    "def test_Factor_from_wide_data():\n",
    "    assert False\n",
    "\n",
    "\n",
    "def test_Factor_from_narrow_data():\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_calculate_pairwise_chi2s_for_MMI_item_response_table()\n",
    "test_multiple_mutual_independence_true_using_bonferroni()\n",
    "test_multiple_mutual_independence_true_using_rao_scott_2()\n",
    "test_calculate_pairwise_chi2s_for_SPMI_item_response_table()\n",
    "test_spmi_true_using_bonferroni()\n",
    "test_spmi_true_using_rao_scott_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hillary_Clinton</th>\n",
       "      <th>Donald_Trump</th>\n",
       "      <th>Jill_Stein</th>\n",
       "      <th>Gary_Johnson</th>\n",
       "      <th>None_Of_The_Above</th>\n",
       "      <th>I_Probably_Wont_Vote</th>\n",
       "      <th>Hillary_Clinton_is_involved_in_many_coverups</th>\n",
       "      <th>Trump_changes_his_positions_all_of_the_time</th>\n",
       "      <th>Hillary_Clinton_lied_to_the_families_of_Americans_killed_in_Benghazi</th>\n",
       "      <th>Trump_is_a_successful_businessman</th>\n",
       "      <th>Trumps_temper_could_get_the_country_into_trouble</th>\n",
       "      <th>I_wish_another_candidate_had_won_the_primary</th>\n",
       "      <th>Need_to_do_more_research</th>\n",
       "      <th>Dont_like__any_candidate</th>\n",
       "      <th>Not_sure_which_candidate_shares_my_values</th>\n",
       "      <th>Waiting_for_debates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hillary_Clinton  Donald_Trump  Jill_Stein  Gary_Johnson  None_Of_The_Above  \\\n",
       "0              0.0           0.0         0.0           0.0                1.0   \n",
       "1              0.0           0.0         0.0           0.0                1.0   \n",
       "2              1.0           0.0         0.0           0.0                0.0   \n",
       "3              0.0           1.0         0.0           0.0                0.0   \n",
       "4              1.0           0.0         0.0           0.0                0.0   \n",
       "\n",
       "   I_Probably_Wont_Vote  Hillary_Clinton_is_involved_in_many_coverups  \\\n",
       "0                   0.0                                           0.0   \n",
       "1                   0.0                                           0.0   \n",
       "2                   0.0                                           0.0   \n",
       "3                   0.0                                           0.0   \n",
       "4                   0.0                                           1.0   \n",
       "\n",
       "   Trump_changes_his_positions_all_of_the_time  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   Hillary_Clinton_lied_to_the_families_of_Americans_killed_in_Benghazi  \\\n",
       "0                                                0.0                      \n",
       "1                                                0.0                      \n",
       "2                                                0.0                      \n",
       "3                                                0.0                      \n",
       "4                                                0.0                      \n",
       "\n",
       "   Trump_is_a_successful_businessman  \\\n",
       "0                                1.0   \n",
       "1                                0.0   \n",
       "2                                0.0   \n",
       "3                                0.0   \n",
       "4                                0.0   \n",
       "\n",
       "   Trumps_temper_could_get_the_country_into_trouble  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               1.0   \n",
       "\n",
       "   I_wish_another_candidate_had_won_the_primary  Need_to_do_more_research  \\\n",
       "0                                           0.0                       0.0   \n",
       "1                                           0.0                       1.0   \n",
       "2                                           0.0                       1.0   \n",
       "3                                           0.0                       0.0   \n",
       "4                                           0.0                       0.0   \n",
       "\n",
       "   Dont_like__any_candidate  Not_sure_which_candidate_shares_my_values  \\\n",
       "0                       0.0                                        1.0   \n",
       "1                       0.0                                        0.0   \n",
       "2                       0.0                                        0.0   \n",
       "3                       0.0                                        0.0   \n",
       "4                       1.0                                        0.0   \n",
       "\n",
       "   Waiting_for_debates  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  1.0  \n",
       "4                  0.0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.datasets import presidential2016\n",
    "\n",
    "data = sm.datasets.presidential2016.load_pandas()\n",
    "data.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2565046672587634e-18"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_factor = Factor(data.data.iloc[:, 11:], data.data.columns[11:], \"reasons_undecided\", orientation=\"wide\")\n",
    "columns_factor = Factor(data.data.iloc[:, 6:11], data.data.columns[6:11], \"believe_true\", orientation=\"wide\")\n",
    "multiple_response_table = MRCVTable([rows_factor,], [columns_factor])\n",
    "table_p_value = multiple_response_table._test_for_single_pairwise_mutual_independence_using_rao_scott_2(rows_factor, columns_factor)\n",
    "assert table_p_value - 6.2565046672587634e-18 <= 0.000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_allclose(table_p_value.values.astype(np.float64), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.20834933e-02,   1.98904185e-01,   1.50952071e-02,\n",
       "          2.43271486e-01,   1.47896365e-03],\n",
       "       [  1.01169167e-02,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00],\n",
       "       [  8.08886522e-04,   1.00000000e+00,   4.50746797e-02,\n",
       "          3.88574715e-02,   4.33464302e-05],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   8.58787906e-02],\n",
       "       [  5.59553004e-01,   1.00000000e+00,   1.51144522e-03,\n",
       "          8.53173376e-01,   1.00000000e+00]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellwise_p_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:statsmodels-dev]",
   "language": "python",
   "name": "conda-env-statsmodels-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
